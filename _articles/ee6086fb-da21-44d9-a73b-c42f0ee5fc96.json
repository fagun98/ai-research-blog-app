{
  "articleName":"Whisper Leak: a side-channel attack on Large Language Models",
  "articleText":"## Chatting Secrets with AI? Whisper Leak Exposed!\n\nAre you comfortable chatting about private matters online, knowing no one can listen in on our digital whispers? Not so fast. Researchers at Microsoft uncovered a sneaky way that your conversations might still be spotted - through the rhythm of how an AI responds to you! \n\nImagine this: You're talking with Siri or Alexa, and they answer word by word as if typing it out one letter at a time, right? Each piece of information they send is a data packet. An eavesdropper can't see what's inside these packets without breaking encryption - but they can notice the size and timing of each packet!\n\nResearchers tested this with AI models. They asked 28 popular AI chatbots questions ranging from fun riddles to serious money laundering queries while keeping their conversations secret. To everyoneâ€™s surprise, most could predict the topic accurately over 98% of the time - just by guessing when a packet was sent!\n\nThis is called Whisper Leak. It's not about breaking the AI but figuring out what you were chatting about based on how it responds. A serious reminder that your online privacy isn't as safe as it seems.\n\nWhisper Leak highlights two important aspects: 1) The way AI chats can reveal much more than we think, and 2) Companies like OpenAI are working to make these leaks less dangerous by adding extra security measures like padding or batching responses in groups.\n\nIn conclusion, this paper shows how even the smallest details of our digital conversations can reveal more about us than we realize. It's a wake-up call for anyone chatting online; always remember that every whisper counts!",
  "articleTags":["AI SAFETY","CYBERSECURITY","DATA PRIVACY","AI ETHICS","AI SECURITY"],
  "articleUrl": "http://arxiv.org/pdf/2511.03675v1",
  "date": "2025-11-21"
}